# -*- coding: utf-8 -*-
"""Untitled11.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1A4Uwodeebp8tT1LHor0gp_CUbp6rfbBV
"""

import pandas as pd
import psycopg2
from sqlalchemy import create_engine
import time

# --- Configuration for your PostgreSQL database ---
db_host = "localhost" # Or your PostgreSQL server IP/hostname
db_name = "meesho_project" # The database you just created in pgAdmin
db_user = "postgres" # Your PostgreSQL username (default is postgres)
db_password = "resonance" # IMPORTANT: Replace with your actual password
db_port = "5432" # Default PostgreSQL port

# Path to your cleaned and merged CSV file
csv_file_path = "olist_ecommerce_merged_cleaned.csv"

# A helper function to check the database connection
def check_db_connection(host, port, user, password, dbname, max_retries=5, delay=5):
    """
    Checks if a connection to the database can be established.
    Implements a simple retry mechanism with exponential backoff.
    """
    for i in range(max_retries):
        try:
            conn = psycopg2.connect(host=host, port=port, user=user, password=password, dbname=dbname)
            conn.close()
            print(f"Connection to database '{dbname}' successful!")
            return True
        except psycopg2.OperationalError as e:
            print(f"Attempt {i+1}/{max_retries}: Connection failed. Retrying in {delay} seconds...")
            print(f"Error details: {e}")
            time.sleep(delay)
            delay *= 2  # Exponential backoff
    print("All connection attempts failed. Please check your PostgreSQL server status and credentials.")
    return False

print(f"Attempting to load data from '{csv_file_path}' into PostgreSQL...")

try:
    # First, check if the database connection is possible
    if not check_db_connection(db_host, db_port, db_user, db_password, db_name):
        raise ConnectionError("Could not establish a connection to the PostgreSQL server.")

    # Create a SQLAlchemy engine to connect to PostgreSQL
    engine = create_engine(f'postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}')

    # Load the cleaned CSV into a Pandas DataFrame
    df_to_load = pd.read_csv(csv_file_path)

    # Convert datetime columns to a format compatible with PostgreSQL's TIMESTAMP
    datetime_cols = [
        'order_purchase_timestamp', 'order_approved_at',
        'order_delivered_carrier_date', 'order_delivered_customer_date',
        'order_estimated_delivery_date', 'shipping_limit_date'
    ]
    for col in datetime_cols:
        if col in df_to_load.columns:
            # We convert to a naive datetime to prevent timezone errors
            df_to_load[col] = pd.to_datetime(df_to_load[col], errors='coerce').dt.tz_localize(None)

    # Define the table name in PostgreSQL
    table_name = "olist_ecommerce_data"

    # Load the DataFrame into PostgreSQL
    # if_exists='replace' will drop the table if it exists and create a new one
    # index=False prevents Pandas from writing the DataFrame index as a column in the DB
    df_to_load.to_sql(table_name, engine, if_exists='replace', index=False)

    print(f"Successfully loaded '{csv_file_path}' into table '{table_name}' in '{db_name}'.")

except FileNotFoundError:
    print(f"Error: The file '{csv_file_path}' was not found. Please ensure it's in the correct directory.")
except ConnectionError as e:
    print(f"Failed to load data: {e}")
except Exception as e:
    print(f"An unexpected error occurred: {e}")